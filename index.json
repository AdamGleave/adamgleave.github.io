[{"authors":["AaronTucker"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"dc406be0fd2f12ba4a472ab24be1ace1","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Aaron Tucker","type":"authors"},{"authors":["AdamGleave"],"categories":null,"content":"I am an artificial intelligence (AI) PhD candidate at UC Berkeley, advised by Stuart Russell. My goal is to develop techniques necessary for advanced automated systems to verifiably act according to human preferences, even in situations unanticipated by their designer. I am particularly interested in improving methods for value learning, and robustness of deep RL.\nI work closely with the Center for Human-Compatible AI, a cross-disciplinary research centre. Prior to joining Berkeley, I had the pleasure of working with Zoubin Ghahramani and Christian Steinruecken during my Master\u0026rsquo;s degree in the Machine Learning Group at the University of Cambridge. Please see my CV for a more comprehensive list of my prior experience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594088090,"objectID":"93e12eca0a1cf520e3ba3783cae166fe","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"I am an artificial intelligence (AI) PhD candidate at UC Berkeley, advised by Stuart Russell. My goal is to develop techniques necessary for advanced automated systems to verifiably act according to human preferences, even in situations unanticipated by their designer.","tags":null,"title":"Adam Gleave","type":"authors"},{"authors":["ChristianSteinruecken"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"abd45ec1fee88028e634200371bffdd8","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Christian Steinruecken","type":"authors"},{"authors":["CodyWild"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"9b505797ffd885d7224d9e7fd9ad0b34","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Cody Wild","type":"authors"},{"authors":["DylanHadfieldMenell"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"b2269b9f1fba7e2549e3203d405d0ce4","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Dylan Hadfield-Menell","type":"authors"},{"authors":["IonelGog"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"04e8428f846d47a164dd7fa4e455ba34","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Ionel Gog","type":"authors"},{"authors":["JanLeike"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"47a66ef93ba0c3eeb9b2fe66c16c8907","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Jan Leike","type":"authors"},{"authors":["MalteSchwarzkopf"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"cab2f97c225b1f007b00c5a4f27303a6","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Malte Schwarzkopf","type":"authors"},{"authors":["MichaelDennis"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"f90ef86318c705b936a8a7ad7ea13d1a","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Michael Dennis","type":"authors"},{"authors":["NeelKant"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"3db53a8e70d8f7156ca88aee3d931df4","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Neel Kant","type":"authors"},{"authors":["OliverHabryka"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"7eee1a5445e577f5bb7cf41ce256862c","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Oliver Habryka","type":"authors"},{"authors":["RobertWatson"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"e3cef9ae48311deb4e5bf051ecd16409","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Robert Watson","type":"authors"},{"authors":["Rohin Shah"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"a00c131ed93e0330f9a274a56fb9636b","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Rohin Shah","type":"authors"},{"authors":["Sergey Levine"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"0a852cccb0f636dd961ce15ceec5f060","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Sergey Levine","type":"authors"},{"authors":["ShaneLegg"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"5a878ce3b4a51724cb4ad05e855cc37b","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Shane Legg","type":"authors"},{"authors":["SorenMindermann"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"21883ef61074aa1c5e9397b6ec9a9ed6","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Sören Mindermann","type":"authors"},{"authors":["StevenHand"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"1654de093fe1dad28754eb37a600ab00","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Steven Hand","type":"authors"},{"authors":["StuartRussell"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1594166737,"objectID":"85858b625e97c85bfc4b9277a71b771d","permalink":"https://gleave.me/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"","tags":null,"title":"Stuart Russell","type":"authors"},{"authors":["Adam Gleave"],"categories":null,"content":" LaTeX is the typesetting system of choice in most STEM fields \u0026ndash; indeed, many computer science venues only accept submissions produced by LaTeX. Unlike What You See Is What You Get (WYSIWYG) word processors, in LaTeX one is writing source code that LaTeX will then compile into a document, such as a PDF. Once mastered, LaTeX can be more flexible and efficient than alternatives, however it comes with a steep learning curve. There exist many excellent introductions to LaTeX. However, I\u0026rsquo;ve found that even experienced LaTeX users often fall prey to many gotchas, or fail to exploit some powerful aspects of the language.\nThis document aims to collect together  design patterns in LaTeX that enable efficient and clear writing, and warn of anti-patterns which interfere with this goal. Take these patterns as suggestions, not strict rules. What may be a pattern in one document can be an anti-pattern in another: for example, defining macros for notation may be beneficial in a PhD thesis, but is likely overkill for an extended abstract. Furthermore, while I anticipate these suggestions to be applicable to many LaTeX users, most of my experience has been in preparing papers for machine learning and computer science. When in doubt, defer to the publication norms of the field you operate in.\nI am indebted to my advisors throughout the years patiently correcting my own writing, especially Jan Leike and Malte Schwarzkopf. I would also like to thank Cody Wild and others for contributing their own suggestions to this list.\nLaTeX As Software Engineering LaTeX is highly extensible (indeed, the language is Turing complete). This suggests treating writing LaTeX documents similar to software engineering. The analogy is not perfect: software must often be maintained for decades or more, whereas hopefully your paper will be published sooner than this! Nonetheless, there are some similar design patterns.\n Don\u0026rsquo;t Repeat Yourself (DRY): Define LaTeX macros for repeated functionality. A common example of repeated LaTeX code is in mathematical notation. Perhaps you start by writing your document using $P$ everywhere for probability. One day, you decide $\\mathbb{P}$ would be clearer. A find-and-replace of every occurrence of P in your document would have many false positives. You are left painstakingly working through your document and, since to err is human, you will likely end up with inconsistent notation. Instead, save yourself some time \u0026ndash; define \\newcommand{\\probability}{P} at the start, and you can easily change notation later to your heart\u0026rsquo;s content.\nAnother source of duplicated code are theorems that must be presented multiple times in the document: for example, the statement in the main body and a proof in an appendix. Instead, use tools to recall an earlier statement of the theorem. Similarly, if you have boilerplate duplicated across figure captions (for example, the same legend), define a macro to consolidate it.\nPay Attention To Errors and Warnings: The LaTeX compiler issues warnings for a variety of common problems, such as citations to undefined references. I encourage immediately fixing these warnings or, if they are spurious, suppressing them. Having zero warnings by default makes it immediately noticeable when an edit has caused a new issue, enabling you to fix the problem immediately when the code is fresh in your mind.\nErrors should always be fixed immediately. Unfortunately, the otherwise excellent Overleaf cloud IDE encourages sloppy practices here, by allowing LaTeX to continue compiling a document after an error. The problem is the LaTeX compiler is often unable to recover from an error, causing the rest of the parse tree to be incorrect, and causing far-reaching and hard to predict effects. Fix errors as they occur so you can focus on writing and not debugging.\nAutomated Checks: In a similar vein, use automated checks to catch common mistakes. This doesn\u0026rsquo;t have to be limited to code \u0026ndash; you can also use or develop tools to automatically check your writing. A spellchecker is a simple example, but you can be more creative: for example, Matt Might wrote shell scripts to check for passive voice, weasel words and lexical illusions.\nUse and Master an IDE: Find an integrated development environment (IDE) for LaTeX that works for you. I like to use Overleaf when collaboratively editing due to its real-time synchronization and commenting. However, I find Overleaf to be lacking in features and compile notably slower than on a local machine, so I also use the TeXiFy IDEA plugin for IntelliJ. There are many other excellent IDEs, though \u0026ndash; the main thing is to pick one and master it.\nUse Source Control: This should go without saying, but do use a version control system like Git and regularly push changes. Sooner or later, you will delete or otherwise corrupt your files, and will be very glad you have this. I also find it cognitively liberating: I can make substantial edits, knowing it will be easy to revert to a previous version if I want. I find this particularly valuable when working on multiple versions of a document at once \u0026ndash; for example, a workshop and conference version \u0026ndash; since I can make edits on multiple branches and merge them. If you use Overleaf then you may be satisfied with it\u0026rsquo;s built-in version control, however I still prefer using Git with Overleaf since this offers more powerful version control and allows one to make edits both locally and in the cloud.\nMathematics LaTeX has excellent support for typesetting mathematical formulas, and so is widely used in mathematics and related disciplines.\nPunctuate Your Math: Mathematics forms an integral part of your text, and should be punctuated accordingly. For example, if your sentence ends with an equation, the equation should end with a period. It can often be helpful to imagine punctuating everything as if it was inline math ($...$), even if you are using display math ($$...$$ or \\begin{equation}...\\end{equation}). Stack Exchange has a good discussion on this.\nUse Detexify: More a tip than a design pattern. If you know how a symbol is written but do not know the LaTeX command to produce it, you can sketch the symbol on Detexify to find it.\nTypography LaTeX encourages writers to specify the structure of the document, and leave formatting details to LaTeX. This usually works well, however there are some common problems that can mislead LaTeX into producing the wrong output.\n Be Semantic: If you want to emphasize some text, use \\emph{}. Do not use \\textit{}. Though they may seem to produce the same effect of italicized text, \\emph{} will automatically switch between italic and Roman: for example, \\emph{emphasis \\emph{nested} works}' produces \u0026ldquo;emphasis nested works\u0026rdquo; whereas \\textit{italics \\textit{is} idempotent} produces \u0026ldquo;italics is idempotent\u0026rdquo;. This behaviour of \\emph{} is useful since environments (such as \\begin{theorem}) may italicize blocks of text, in which case Roman text stands out from the italic surroundings.\n Spacing after abbreviation periods: LaTeX adds extra space between sentences. This improves readability, but LaTeX can misinterpret periods in abbreviations as being the end of a sentence: for example, in e.g. this LaTeX will insert a sentence space after e.g.. To avoid this problem, use \\  to instruct LaTeX to use a regular space: e.g.\\ this. More rarely, LaTeX may incorrectly believe a period does not end a sentence, for example after a capital letter: in this case, you can force it using \\@ as in LaTeX was invented in the US\\@.\n Use ` and ' Quote Marks: Use ` and ' at the left and right end of single quotes, and `` and '' for double quotes. This allows LaTeX to generate appropriate quotation characters. Be consistent with single vs double quotes within a document.\nFigures LaTeX has excellent support for figures, both in the form of float environments and packages to include external graphics or even generate vector figures inside your document.\nUse Vector Graphics: Wherever possible, generate figures as vector graphics such as SVG or PDF rather than raster graphics formats such as PNG. Vector graphics can be visualized at arbitrarily high resolutions without any loss of fidelity \u0026ndash; this will allow your readers to zoom in on plots to better read them, and print your paper in a high quality. They also tend to be smaller than saving the file as raster graphics. It is almost always possible to save plots and schematic diagrams as vector graphics. Raster graphics are appropriate for figures such as photographs or screenshots.\nMatch the Paper Style: Even though you will often be generating your figures outside of LaTeX in a package like matplotlib, to the reader your figures are an integral part of the paper. Accordingly, you should use the same font and \u0026ndash; where possible \u0026ndash; font size as in the rest of the paper. It\u0026rsquo;s particularly important to save your figures with the same geometric dimensions as they will be embedded in the paper. While LaTeX does support rescaling included graphics, this will make it impossible to match font sizes exactly. Moreover, many packages like matplotlib will adjust the figure based on the size, adding more tick labels when the figure is larger \u0026ndash; giving it the right dimensions will help optimize the figure for clarity at the target size.\nMake each Figure Self Contained: Readers will often skip ahead to figures without reading all the context, or will have forgotten some of the relevant context by the time they get to your figure. As far as practical, make each figure comprehensible in isolation. In particular, include clear axis labels, a legend and specify any extra information needed to understand the figure in the caption. Some people go as far as to aim for the key points of their paper to be understood just by reading the figures and captions!\nCitations and References As LaTeX was designed around the needs of academic documents, it has extensive support for citations. However, there are a number of subtle details it is important to get right.\nUse BibLaTeX Where Possible: BibLaTeX ( guide) is the most modern approach to bibliography management in LaTeX, designed as a replacement for BibTeX ( guide). BibLaTeX adds many useful features, such as new entry types like @online and localization in several languages. However, often you won\u0026rsquo;t have a choice \u0026ndash; if you are submitting to a conference or journal, their LaTeX style file will usually specify a particular bibliography manager.\nUse The Right Citation Command: In particular, it is important to distinguish between parenthetical citations (Gleave et al, 2020) v.s. in-text citations, claims Gleave et al (2020). For parenthetical citations, use \\parencite (BibLaTeX) or \\citep (BibTeX); for in-text citations, use \\textcite (BibLaTeX) or \\citet (BibTeX). Avoid nested brackets: use \\citep[see]{gleave2020} to produce \u0026ldquo;(see Gleave et al, 2020)\u0026rdquo;, rather than (see~\\citep{gleave2020}) producing \u0026ldquo;(see (Gleave et al, 2020))\u0026rdquo;.\nUse Non-Breaking Spaces: Citations should be on the same line as the word or sentence they are attached to, so use the non-breaking space ~ to instruct LaTeX to avoid orphaning the citation, as in Knuth developed LaTeX~\\citep{latex}.\nBibliography Management: A sloppy bibliography is often symptomatic of a sloppy paper and, rightly or wrongly, readers (and reviewers!) may judge you for this. A common problem is LaTeX reformatting the capitalization of paper titles. This is usually desirable, since it ensures consistency across bibliography entries. However, it is undesirable when the title includes an acronym: these should be guarded with {}, as in {DQN}. It is also important to choose the correct entry type, for example @inproceedings for a conference, @article for a journal and @misc for preprints. Finally, it is essential to be consistent in your bibliography. Author names should always be spelt the same way (look out for middle initials, abbreviations); conference and journal names should always be abbreviated or spelt out in full; you should always include DOI links or never.\n","date":1598227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598316549,"objectID":"156581094eb66194befefa2b74082860","permalink":"https://gleave.me/post/latex-design-patterns/","publishdate":"2020-08-24T00:00:00Z","relpermalink":"/post/latex-design-patterns/","section":"post","summary":"LaTeX is the typesetting system of choice in most STEM fields. Yet even experienced LaTeX users often fall prey to many gotchas, or fail to exploit some powerful aspects of the language. In this document, I collect together *design patterns* to help efficiently produce clear LaTeX documents.","tags":null,"title":"Writing Beautifully in LaTeX","type":"post"},{"authors":["Adam Gleave","Michael Dennis","Shane Legg","Stuart Russell","Jan Leike"],"categories":null,"content":"","date":1592956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166737,"objectID":"c469edaeeccd97e5ecd07654375ed555","permalink":"https://gleave.me/publication/2020-06-quantifying-differences/","publishdate":"2020-06-24T00:00:00Z","relpermalink":"/publication/2020-06-quantifying-differences/","section":"publication","summary":"For many tasks, the reward function is too complex to be specified procedurally, and must instead be learned from user data. Prior work has evaluated learned reward functions by examining rollouts from a policy optimized for the learned reward. However, this method cannot distinguish between the learned reward function failing to reflect user preferences, and the reinforcement learning algorithm failing to optimize the learned reward. Moreover, the rollout method is highly sensitive to details of the environment the learned reward is evaluated in, which often differ in the deployment environment. To address these problems, we introduce the Equivalent-Policy Invariant Comparison (EPIC) distance to quantify the difference between two reward functions directly, without training a policy. We prove EPIC is invariant on an equivalence class of reward functions that always induce the same optimal policy. Furthermore, we find EPIC can be precisely approximated and is more robust than baselines to the choice of visitation distribution. Finally, we find that the EPIC distance of learned reward functions to the ground-truth reward is predictive of the success of training a policy, even in different transition dynamics. Our source code is available at https://github.com/HumanCompatibleAI/evaluating-rewards/.","tags":null,"title":"Quantifying Differences in Reward Functions","type":"publication"},{"authors":["Adam Gleave","Michael Dennis","Cody Wild","Neel Kant","Sergey Levine","Stuart Russell"],"categories":null,"content":"","date":1581292800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594169411,"objectID":"289cdf242f098b48f13221ed6d225578","permalink":"https://gleave.me/publication/2020-04-adversarial-policies/","publishdate":"2020-02-10T00:00:00Z","relpermalink":"/publication/2020-04-adversarial-policies/","section":"publication","summary":"Deep reinforcement learning (RL) policies are known to be vulnerable to adversarial perturbations to their observations, similar to adversarial examples for classifiers. However, an attacker is not usually able to directly modify another agent's observations. This might lead one to wonder: is it possible to attack an RL agent simply by choosing an adversarial policy acting in a multi-agent environment so as to create natural observations that are adversarial? We demonstrate the existence of adversarial policies in zero-sum games between simulated humanoid robots with proprioceptive observations, against state-of-the-art victims trained via self-play to be robust to opponents. The adversarial policies reliably win against the victims but generate seemingly random and uncoordinated behavior. We find that these policies are more successful in high-dimensional environments, and induce substantially different activations in the victim policy network than when the victim plays against a normal opponent. Videos are available at https://adversarialpolicies.github.io/.","tags":null,"title":"Adversarial Policies: Attacking Deep Reinforcement Learning","type":"publication"},{"authors":["Aaron Tucker","Adam Gleave","Stuart Russell"],"categories":null,"content":"","date":1542672000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166737,"objectID":"80eabed0dfc9aada3fd6baac9db092d2","permalink":"https://gleave.me/publication/2018-12-irl-video-games/","publishdate":"2018-11-20T00:00:00Z","relpermalink":"/publication/2018-12-irl-video-games/","section":"publication","summary":"Deep reinforcement learning achieves superhuman performance in a range of video game environments, but requires that a designer manually specify a reward function. It is often easier to provide demonstrations of a target behavior than to design a reward function describing that behavior. Inverse reinforcement learning (IRL) algorithms can infer a reward from demonstrations in low-dimensional continuous control environments, but there has been little work on applying IRL to high-dimensional video games. In our CNN-AIRL baseline, we modify the state-of-the-art adversarial IRL (AIRL) algorithm to use CNNs for the generator and discriminator. To stabilize training, we normalize the reward and increase the size of the discriminator training dataset. We additionally learn a low-dimensional state representation using a novel autoencoder architecture tuned for video game environments. This embedding is used as input to the reward network, improving the sample efficiency of expert demonstrations. Our method achieves high-level performance on the simple Catcher video game, substantially outperforming the CNN-AIRL baseline. We also score points on the Enduro Atari racing game, but do not match expert performance, highlighting the need for further work.","tags":null,"title":"Inverse Reinforcement Learning for Video Games","type":"publication"},{"authors":["Adam Gleave","Oliver Habryka"],"categories":null,"content":"","date":1531612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166737,"objectID":"6e900e7b012e313b4f8b4aca8a1a62ff","permalink":"https://gleave.me/publication/2018-06-multi-task-irl/","publishdate":"2018-07-15T00:00:00Z","relpermalink":"/publication/2018-06-multi-task-irl/","section":"publication","summary":"Multi-task Inverse Reinforcement Learning (IRL) is the problem of inferring multiple reward functions from expert demonstrations. Prior work, built on Bayesian IRL, is unable to scale to complex environments due to computational constraints. This paper contributes a formulation of multi-task IRL in the more computationally efficient Maximum Causal Entropy (MCE) IRL framework. Experiments show our approach can perform one-shot imitation learning in a gridworld environment that single-task IRL algorithms need hundreds of demonstrations to solve. We outline preliminary work using meta-learning to extend our method to the function approximator setting of modern MCE IRL algorithms. Evaluating on multi-task variants of common simulated robotics benchmarks, we discover serious limitations of these IRL algorithms, and conclude with suggestions for further work","tags":null,"title":"Multi-task Maximum Causal Entropy Inverse Reinforcement Learning","type":"publication"},{"authors":["Sören Mindermann","Rohin Shah","Adam Gleave","Dylan Hadfield-Menell"],"categories":null,"content":"","date":1531526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166737,"objectID":"efba9859261dcac58a40f3d6880f62b8","permalink":"https://gleave.me/publication/2018-06-active-ird/","publishdate":"2018-07-14T00:00:00Z","relpermalink":"/publication/2018-06-active-ird/","section":"publication","summary":"Reward design, the problem of selecting an appropriate reward function for an AI system, is both critically important, as it encodes the task the system should perform, and challenging, as it requires reasoning about and understanding the agent’s environment in detail. AI practitioners often iterate on the reward function for their systems in a trial-and-error process to get their desired behavior. Inverse reward design (IRD) is a preference inference method that infers a true reward function from an observed, possibly misspecified, proxy reward function. This allows the system to determine when it should trust its observed reward function and respond appropriately. This has been shown to avoid problems in reward design such as negative side-effects (omitting a seemingly irrelevant but important aspect of the task) and reward hacking (learning to exploit unanticipated loopholes). In this paper, we actively select the set of proxy reward functions available to the designer. This improves the quality of inference and simplifies the associated reward design problem. We present two types of queries: discrete queries, where the system designer chooses from a discrete set of reward functions, and feature queries, where the system queries the designer for weights on a small set of features. We evaluate this approach with experiments in a personal shopping assistant domain and a 2D navigation domain. We find that our approach leads to reduced regret at test time compared with vanilla IRD. Our results indicate that actively selecting the set of available reward functions is a promising direction to improve the efficiency and effectiveness of reward design.","tags":null,"title":"Active Inverse Reward Design","type":"publication"},{"authors":["Adam Gleave","Christian Steinruecken"],"categories":null,"content":"","date":1490486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166737,"objectID":"9e12ff34887234a3a64cba8e16456a33","permalink":"https://gleave.me/publication/2017-unicode-compression/","publishdate":"2017-03-26T00:00:00Z","relpermalink":"/publication/2017-unicode-compression/","section":"publication","summary":"The majority of online content is written in languages other than English, and is most commonly encoded in UTF-8, the world’s dominant Unicode character encoding. Traditional compression algorithms typically operate on individual bytes. While this approach works well for the single-byte ASCII encoding, it works poorly for UTF-8, where characters often span multiple bytes. Our paper introduces a technique to modify byte-by-byte compressors to operate directly on Unicode characters. We demonstrate this technique applied to LZW and PPM, finding our variant substantially outperforms the original unmodified compressors.","tags":null,"title":"Making Compression Algorithms for Unicode Text","type":"publication"},{"authors":["Ionel Gog","Malte Schwarzkopf","Adam Gleave","Robert Watson","Steven Hand"],"categories":null,"content":"","date":1478044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166737,"objectID":"6dbb17688848e82bc5938bbb88a74310","permalink":"https://gleave.me/publication/2016-firmament/","publishdate":"2016-11-02T00:00:00Z","relpermalink":"/publication/2016-firmament/","section":"publication","summary":"Centralized datacenter schedulers can make high-quality placement decisions when scheduling tasks in a cluster. Today, however, high-quality placements come at the cost of high latency at scale, which degrades response time for interactive tasks and reduces cluster utilization.This paper describes Firmament, a centralized scheduler that scales to over ten thousand machines at subsecond placement latency even though it continuously reschedules all tasks via a min-cost max-flow (MCMF) optimization. Firmament achieves low latency by using multiple MCMF algorithms, by solving the problem incrementally, and via problem-specific optimizations. Experiments with a Google workload trace from a 12,500-machine cluster show that Firmament improves placement latency by 20× over Quincy, a prior centralized scheduler using the same MCMF optimization. Moreover, even though Firmament is centralized, it matches the placement latency of distributed schedulers for workloads of short tasks. Finally, Firmament exceeds the placement quality of four widely-used centralized and distributed schedulers on a real-world cluster, and hence improves batch task response time by 6×.","tags":null,"title":"Firmament: Fast, Centralized Cluster Scheduling at Scale","type":"publication"}]